# Отчет о проделанной работе Бунина Дмитрия

### ABSA

#### English

Сначала я решал задачу ABSA (Aspect Based Sentiment Analysis), что соответствует задаче E исходного соревнования. За основу была взята статья (Attention-based LSTM for Aspect-level Sentiment Classification). По статье были реализованы модели:
* AE-LSTM (1-db-ae-lstm.ipynb)
* AT-LSTM (2-db-at-lstm.ipynb)
* ATAE-LSTM (3-db-atae-lstm.ipynb)

В точности добиться результатов статьи не удалось, возможно, авторы использовали какие-то хитрости в обучении моделей. 

#### Russian

Затем ATAE-LSTM была перенесена на русский язык (4-db-at-atae-lstm-russian.ipynb). Были использованы русскоязычные эмбеддинги из RusVectōrēs с соответствующим препроцессингом текста (лемматизация и разбиение по частям речи).

Результаты (MacroF1):

Model | F1-Macro
--- | ---
Best competition | 0.458
ATAE-LSTM | 0.446

Best competition -- лучшая модель на соревновании (результаты соревнования см. в references/SentiRuEval_results.xlsx).


### ATSC

Было решено переключиться на задачу ATSC (Aspect-Target Sentiment Classification), согласно пожеланиям ментора, что соответствует задаче C исходного соревнования. Я занимался исследованием применимости модели ELMo для решения такой задачи. 


#### English

На английском датасете были испытаны следующие архитектуры:

* ELMOClassifierByToken -- из исходного предложения выделялась группа исследуемых токенов (относительно них надо определить тональность), эмбеддинги ELMo по этим токенам усреднялись, и результат подавался на вход FC-слою.
* ELMOClassifierByContext -- в противопоставление первой модели, FC-слою подавалась конкатенация average-global-pooling и max-global-pooling от всех токенов кроме токенов, относительно которых требуется определить тональность.
* ELMoCNN -- здесь, как и в предыдущей модели использовались токены контекста, но они пропускались через один слой CNN (как в Assignment-2). Эта модель показала самый лучший результат для англоязычного датасета.

Результаты:
Model | Accuracy | F1-Macro
--- | --- | ---
SOTA | 0.871 | 0.801
ELMOClassifierByToken-1 | 0.740 | 0.613
ELMOClassifierByContext-2 | 0.729 | 0.618
ELMoCNN | 0.807 | 0.707

Под SOTA подразумевается результат из статьи Adapt or Get Left Behind:Domain Adaptation through BERT Language Model Finetuning forAspect-Target Sentiment Classification.

#### Russian

Затем я попробовал применить ELMoCNN для русского языка. Для этого надо было выбрать эмбеддинги ELMo.

Сначала были использованы эмбеддинги DeepPavlov (8-db-elmo-russian-1.ipynb), но с ними не удалось получить хорошие результаты. Наверное, где-то была ошибка с обработкой эмбеддингов, потому что я их получал не в процессе обучения, а заранее (из-за конфликта между tf, Pytorch на одной машине).

В итоге выбор остановился на эмбеддингах из RusVectōrēs (8-db-elmo-russian-2.ipynb). Было два варианта: эмбеддинги лемм или эмбеддинги токенов. Пока использовались только эмбеддинги для токенов.

Были получены следующие результаты:

Model | F1-Micro | F1-Macro
--- | --- | ---
Best competition | 0.825 | 0.555
ELMoCNN-1 | 0.855 | 0.520
ELMoCNN-2 | 0.851 | 0.521

Best competition -- лучшая модель на соревновании (результаты соревнования см. в references/SentiRuEval_results.xlsx).

ELMoCNN-1 отличается от ELMoCNN-2 способом обработки дисбаланса классов. Первая модель делает это при помощи взвешивания лосса обратно пропорционально частоте классов. Вторая модель делает это при помощи Random Oversampling на уровне генерации минибатча. К сожалению, проблему с дисбалансом классов исправить так и не удалось: модель все равно не угадывает класс `both`, а также весьма часто путает `positive` и `negative`.